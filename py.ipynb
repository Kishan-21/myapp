{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW7DZLguPF9r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> **Welcome to PyTorch Basics**\n",
        "\n",
        "*   Learn what is tensor and how to deal with it.\n",
        "*   Tensor operations\n",
        "*   Work seamlessly with numpy and pytorch\n",
        "*   PyTorch with GPU\n",
        "\n",
        "*   Linear and Logistic Regression using pytorch\n",
        "*   Neural Nets with pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ9hb-6UBclf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDJNDqn1B5b2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "98b80298-50e7-44f8-9da9-6042a2f54ef7"
      },
      "source": [
        "# create a tensor\n",
        "tensor = torch.Tensor([[1, 2], [3, 4]])\n",
        "print(tensor)\n",
        "\n",
        "int_tensor = torch.zeros([2, 2], dtype=torch.int32)\n",
        "print(int_tensor.type())\n",
        "print(tensor.type())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "torch.IntTensor\n",
            "torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifUa-sh5CDvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "67c0f247-e39b-4536-c979-84e95ad8ba77"
      },
      "source": [
        "# shape of the tensor\n",
        "print(tensor.shape)\n",
        "print(tensor.size())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm6Fxe9SCWOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02bcf503-e377-4b3b-c0a5-3e8d402502f9"
      },
      "source": [
        "# create a random tensor\n",
        "empty_tensor = torch.Tensor(2,2)\n",
        "print(empty_tensor)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.5310e+27, 0.0000e+00],\n",
            "        [4.4842e-44, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeHB6zmVCYWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72f6a8b2-0791-4b66-d7ce-d0d42d630643"
      },
      "source": [
        "# create a tensor with value between -1 and 1\n",
        "uniform_tensor = torch.Tensor(2, 2).uniform_(-1, 1)\n",
        "print(uniform_tensor)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4845,  0.2023],\n",
            "        [ 0.7255, -0.3425]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iajWj2PcCa9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae6361f3-e504-4744-ce30-4d0b4dd37a6f"
      },
      "source": [
        "# create a random tensor with values between 0 and 1\n",
        "rand_tensor = torch.rand(2, )\n",
        "print(rand_tensor)\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3282, 0.6194])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Hh5G6OF5L6",
        "colab_type": "text"
      },
      "source": [
        "**Tensor Operation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYve2yUhF0Ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1ff83590-b6fb-49a5-81e3-7da43d728390"
      },
      "source": [
        "# access an element from a tensor\n",
        "print(tensor[0][0]) \n",
        "print(tensor[0][0].item())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRncPfyaGfFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef95fbd0-da9c-430a-b252-1fdfb0eb5c8a"
      },
      "source": [
        "# replace an item at position (1,1)\n",
        "tensor[1][1] = 5\n",
        "print(tensor)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOJG9CoLDTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5c8a5612-1cd9-408c-d6e2-b2c3aed54d26"
      },
      "source": [
        "# create a tensor for slicing operations\n",
        "slicing_tensor = torch.Tensor([[0, 1 , 2], [3, 4, 5]])\n",
        "print(slicing_tensor.shape)\n",
        "\n",
        "# elements from every row and first column\n",
        "print(slicing_tensor[:, 0])\n",
        "\n",
        "# elements from every row and last column\n",
        "print(slicing_tensor[:, -1])\n",
        "\n",
        "# all elements from the first two columns\n",
        "print(slicing_tensor[:, :2])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([0., 3.])\n",
            "tensor([2., 5.])\n",
            "tensor([[0., 1.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVTRF8piMExa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "95260bed-1cb3-46d8-e91f-68374b52c3c1"
      },
      "source": [
        "# reshape a tensor\n",
        "reshape_tensor = torch.Tensor([[0, 1, 2], [3, 4, 5]])\n",
        "print(reshape_tensor.shape)\n",
        "\n",
        "reshape_tensor = reshape_tensor.view(1, 6)\n",
        "print(reshape_tensor)\n",
        "print(reshape_tensor.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[0., 1., 2., 3., 4., 5.]])\n",
            "torch.Size([1, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEEo-8IxOoFe",
        "colab_type": "text"
      },
      "source": [
        "**Bridge between numpy and pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmmiBQLzM3g4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "906a4ff2-7eba-4332-b74f-47b97236f849"
      },
      "source": [
        "import numpy as np\n",
        "# create a numpy array\n",
        "np_ndarray = np.random.randn(2, 2)\n",
        "\n",
        "# convert numpy array to pytorch tensor\n",
        "to_tensor = torch.from_numpy(np_ndarray)\n",
        "print(to_tensor)\n",
        "\n",
        "# convert torch tensor to numpy array\n",
        "to_numpy = to_tensor.numpy()\n",
        "print(to_numpy)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0642, -1.2433],\n",
            "        [ 0.6279,  1.8401]], dtype=torch.float64)\n",
            "[[ 0.06419363 -1.24329566]\n",
            " [ 0.62787306  1.8400619 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1-ArH-iQThq",
        "colab_type": "text"
      },
      "source": [
        "**Basic Tensor Operations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aNMHot4QTNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5e37660-f08a-4cd9-ebd6-4cf589e15871"
      },
      "source": [
        "# transpose a tensor\n",
        "my_tensor = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(my_tensor.shape)\n",
        "\n",
        "my_transposed_tensor = my_tensor.t()\n",
        "print(my_transposed_tensor.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1RbkVdTIpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3594f462-8df7-4dd0-d5e3-62c2aaa9d752"
      },
      "source": [
        "# tensor addition\n",
        "tensor_1 = torch.Tensor([1, 2])\n",
        "tensor_2 = torch.Tensor([2, 1])\n",
        "print(tensor_1 + tensor_2)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XIsEqd5WffH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c88c322b-fcc1-435e-8436-0c0edfb6edfe"
      },
      "source": [
        "# tensor subtraction\n",
        "print(tensor_1 - tensor_2)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.,  1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBqmBYSVQNPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34a0681b-d937-4b37-9895-c7a259ce7ed8"
      },
      "source": [
        "# cross product\n",
        "tensor_1 = torch.Tensor([[1, 2, 3], [3, 4, 5]])\n",
        "tensor_2 = torch.Tensor([[3, 2, 1], [5, 4, 3]])\n",
        "\n",
        "cross_tensor = tensor_1.cross(tensor_2)\n",
        "print(cross_tensor)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.,  8., -4.],\n",
            "        [-8., 16., -8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXfXttQmWlvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70141ee4-f3a6-481d-e8b4-2923cf235c87"
      },
      "source": [
        "# matrix multiplication\n",
        "tensor_1 = torch.Tensor([[1, 0], [0, 1]])\n",
        "tensor_2 = torch.Tensor([[2, 0], [0, 2]])\n",
        "matmul_tensor = tensor_1.mm(tensor_2)\n",
        "print(matmul_tensor)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 0.],\n",
            "        [0., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so16Va25W--8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13c0b675-94d9-441c-8ca9-1d505c5cd84a"
      },
      "source": [
        "# elementwise multiplication\n",
        "tensor_1 = torch.Tensor([1, 2, 3, 4])\n",
        "tensor_2 = torch.Tensor([2, 1, 4, 3])\n",
        "elemmul_tensor = tensor_1.mul(tensor_2)\n",
        "print(elemmul_tensor)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.,  2., 12., 12.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwRjPXw0Y9Ii",
        "colab_type": "text"
      },
      "source": [
        "**GPU/CUDA**\n",
        "\n",
        "> You can accelerate your tensor operations using GPU. Here is how you can do it!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml3FnUHfXmLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bae28bee-6a91-4613-b733-e4de7c478908"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "tensor_1 = torch.Tensor([[1, 0], [0, 1]])\n",
        "tensor_2 = torch.Tensor([[2, 0], [0, 2]])\n",
        "tensor_1 = tensor_1.cuda()\n",
        "tensor_2 = tensor_2.cuda()\n",
        "print(tensor_1.mm(tensor_2))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "tensor([[2., 0.],\n",
            "        [0., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbjdSey9gzPN",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression**\n",
        "\n",
        "```\n",
        "Å¶ = bX + a + e\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqnK9yGJbZnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c624760f-51c1-45dc-8847-dce34e827001"
      },
      "source": [
        "# how to calculate gradient of a variable\n",
        "x = torch.tensor(3., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(1., requires_grad=True)\n",
        "\n",
        "# build the computation graph\n",
        "y = w*x + b\n",
        "\n",
        "# compute gradients\n",
        "y.backward()\n",
        "\n",
        "# print the gradients\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(3.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htoMxE7KicSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "96363bc9-75ae-406c-f21b-b3e305937076"
      },
      "source": [
        "# learn to build loss function and optimiser\n",
        "x = torch.rand(10, 3)\n",
        "y = torch.rand(10, 2)\n",
        "\n",
        "# build a fully connected layer. this is our model\n",
        "linear = torch.nn.Linear(3, 2)\n",
        "\n",
        "print('Weight : ', linear.weight)\n",
        "print('Bias : ', linear.bias)\n",
        "\n",
        "# define loss function and optimiser\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# forward pass\n",
        "pred = linear(x)\n",
        "\n",
        "# compute loss\n",
        "loss = criterion(pred, y)\n",
        "print('Loss: ', loss.item())\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print('dL/dW : ', linear.weight)\n",
        "print('dL/db : ', linear.bias)\n",
        "\n",
        "# update the weight and bias\n",
        "optimiser.step()\n",
        "\n",
        "# print loss after 1 step of SGD\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('Loss : ', loss.item())\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight :  Parameter containing:\n",
            "tensor([[ 0.3938,  0.1538,  0.1772],\n",
            "        [ 0.1885, -0.0399, -0.0179]], requires_grad=True)\n",
            "Bias :  Parameter containing:\n",
            "tensor([-0.1385,  0.5432], requires_grad=True)\n",
            "Loss:  0.12052497267723083\n",
            "dL/dW :  Parameter containing:\n",
            "tensor([[ 0.3938,  0.1538,  0.1772],\n",
            "        [ 0.1885, -0.0399, -0.0179]], requires_grad=True)\n",
            "dL/db :  Parameter containing:\n",
            "tensor([-0.1385,  0.5432], requires_grad=True)\n",
            "Loss :  0.11848536878824234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbJSvVMNmZeu",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression, finally!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUQcfe58jYn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ac116dd3-db04-429e-80d0-132057a8364d"
      },
      "source": [
        "# hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "# toy-dataset\n",
        "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
        "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
        "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
        "\n",
        "y_train = y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
        "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
        "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
        "\n",
        "# linear regression model\n",
        "model = torch.nn.Linear(input_size, output_size)\n",
        "\n",
        "# loss function and optimiser\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "for epoch in range(num_epochs):\n",
        "  # convert numpy array to torch tensors\n",
        "  inputs = torch.from_numpy(x_train)\n",
        "  targets = torch.from_numpy(y_train)\n",
        "\n",
        "  # forward pass\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, targets)\n",
        "\n",
        "  # backward pass\n",
        "  optimiser.zero_grad()\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    print('Epoch [{}/{}], Loss : {:.4f}'.format(epoch, num_epochs, loss.item()))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [4/100], Loss : 0.4557\n",
            "Epoch [9/100], Loss : 0.4485\n",
            "Epoch [14/100], Loss : 0.4414\n",
            "Epoch [19/100], Loss : 0.4344\n",
            "Epoch [24/100], Loss : 0.4277\n",
            "Epoch [29/100], Loss : 0.4211\n",
            "Epoch [34/100], Loss : 0.4147\n",
            "Epoch [39/100], Loss : 0.4085\n",
            "Epoch [44/100], Loss : 0.4024\n",
            "Epoch [49/100], Loss : 0.3965\n",
            "Epoch [54/100], Loss : 0.3907\n",
            "Epoch [59/100], Loss : 0.3851\n",
            "Epoch [64/100], Loss : 0.3796\n",
            "Epoch [69/100], Loss : 0.3742\n",
            "Epoch [74/100], Loss : 0.3690\n",
            "Epoch [79/100], Loss : 0.3639\n",
            "Epoch [84/100], Loss : 0.3590\n",
            "Epoch [89/100], Loss : 0.3542\n",
            "Epoch [94/100], Loss : 0.3495\n",
            "Epoch [99/100], Loss : 0.3449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a736M0pimuLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0076bb7e-1a3b-405e-d305-29ab71e1fb9e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
        "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
        "plt.plot(x_train, predicted, label='Predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlH7X8Xrpy31",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcDVbZ4rpp6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNSg5U8mp_pG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "c9a587ba-d2fe-4daa-ff12-1df011096dfe"
      },
      "source": [
        "# hyper-parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST data (images and labels)\n",
        "train_dataset = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# logistic regression model\n",
        "model = torch.nn.Linear(input_size, num_classes)\n",
        "\n",
        "# loss function and optimiser\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # reshape images to (batch_size, input_size)\n",
        "    images = images.reshape(-1, 28*28)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print('Epoch: [{}/{}], Step: [{}/{}], Loss: {}'.format(epoch+1, num_epochs, (i+1), total_step, loss.item()))\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0/5], Step: [100/600], Loss: 2.275242567062378\n",
            "Epoch: [0/5], Step: [200/600], Loss: 2.1301276683807373\n",
            "Epoch: [0/5], Step: [300/600], Loss: 2.0826468467712402\n",
            "Epoch: [0/5], Step: [400/600], Loss: 1.9868426322937012\n",
            "Epoch: [0/5], Step: [500/600], Loss: 1.933735966682434\n",
            "Epoch: [0/5], Step: [600/600], Loss: 1.8777661323547363\n",
            "Epoch: [1/5], Step: [100/600], Loss: 1.7542041540145874\n",
            "Epoch: [1/5], Step: [200/600], Loss: 1.7108606100082397\n",
            "Epoch: [1/5], Step: [300/600], Loss: 1.668391466140747\n",
            "Epoch: [1/5], Step: [400/600], Loss: 1.567360520362854\n",
            "Epoch: [1/5], Step: [500/600], Loss: 1.4745100736618042\n",
            "Epoch: [1/5], Step: [600/600], Loss: 1.5267373323440552\n",
            "Epoch: [2/5], Step: [100/600], Loss: 1.4290955066680908\n",
            "Epoch: [2/5], Step: [200/600], Loss: 1.372494101524353\n",
            "Epoch: [2/5], Step: [300/600], Loss: 1.3481389284133911\n",
            "Epoch: [2/5], Step: [400/600], Loss: 1.3037468194961548\n",
            "Epoch: [2/5], Step: [500/600], Loss: 1.368414282798767\n",
            "Epoch: [2/5], Step: [600/600], Loss: 1.2571070194244385\n",
            "Epoch: [3/5], Step: [100/600], Loss: 1.217742681503296\n",
            "Epoch: [3/5], Step: [200/600], Loss: 1.177332878112793\n",
            "Epoch: [3/5], Step: [300/600], Loss: 1.166712760925293\n",
            "Epoch: [3/5], Step: [400/600], Loss: 1.1505472660064697\n",
            "Epoch: [3/5], Step: [500/600], Loss: 1.2024507522583008\n",
            "Epoch: [3/5], Step: [600/600], Loss: 1.1310445070266724\n",
            "Epoch: [4/5], Step: [100/600], Loss: 1.1882827281951904\n",
            "Epoch: [4/5], Step: [200/600], Loss: 1.0985058546066284\n",
            "Epoch: [4/5], Step: [300/600], Loss: 1.0408210754394531\n",
            "Epoch: [4/5], Step: [400/600], Loss: 1.0233019590377808\n",
            "Epoch: [4/5], Step: [500/600], Loss: 1.0069011449813843\n",
            "Epoch: [4/5], Step: [600/600], Loss: 1.0102660655975342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM9swXpxvOt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46bc3f29-3f80-492d-af93-c105a8eb2d79"
      },
      "source": [
        "# test the model\n",
        "# in test phase, we don't need the gradients\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "  print('Accuracy of the model on 10000 test images : {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on 10000 test images : 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mia5Lk1aff",
        "colab_type": "text"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMkfqVPhweb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "6e91d880-542a-454a-ab64-1ae9a6de14a6"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter()\n",
        "# device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper-parameter\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST data (images and labels)\n",
        "train_dataset = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST('.data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# fully connected neural net with one hidden layer\n",
        "class NeuralNet(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# loss and optimiser\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # backward pass\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch: [{}/{}], Step: [{}/{}], Loss: '.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/5], Step: [100/600], Loss: \n",
            "Epoch: [1/5], Step: [200/600], Loss: \n",
            "Epoch: [1/5], Step: [300/600], Loss: \n",
            "Epoch: [1/5], Step: [400/600], Loss: \n",
            "Epoch: [1/5], Step: [500/600], Loss: \n",
            "Epoch: [1/5], Step: [600/600], Loss: \n",
            "Epoch: [2/5], Step: [100/600], Loss: \n",
            "Epoch: [2/5], Step: [200/600], Loss: \n",
            "Epoch: [2/5], Step: [300/600], Loss: \n",
            "Epoch: [2/5], Step: [400/600], Loss: \n",
            "Epoch: [2/5], Step: [500/600], Loss: \n",
            "Epoch: [2/5], Step: [600/600], Loss: \n",
            "Epoch: [3/5], Step: [100/600], Loss: \n",
            "Epoch: [3/5], Step: [200/600], Loss: \n",
            "Epoch: [3/5], Step: [300/600], Loss: \n",
            "Epoch: [3/5], Step: [400/600], Loss: \n",
            "Epoch: [3/5], Step: [500/600], Loss: \n",
            "Epoch: [3/5], Step: [600/600], Loss: \n",
            "Epoch: [4/5], Step: [100/600], Loss: \n",
            "Epoch: [4/5], Step: [200/600], Loss: \n",
            "Epoch: [4/5], Step: [300/600], Loss: \n",
            "Epoch: [4/5], Step: [400/600], Loss: \n",
            "Epoch: [4/5], Step: [500/600], Loss: \n",
            "Epoch: [4/5], Step: [600/600], Loss: \n",
            "Epoch: [5/5], Step: [100/600], Loss: \n",
            "Epoch: [5/5], Step: [200/600], Loss: \n",
            "Epoch: [5/5], Step: [300/600], Loss: \n",
            "Epoch: [5/5], Step: [400/600], Loss: \n",
            "Epoch: [5/5], Step: [500/600], Loss: \n",
            "Epoch: [5/5], Step: [600/600], Loss: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycgib-gD69us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55947bd8-5d66-42d6-d1f0-d8972a727e52"
      },
      "source": [
        "# test the model\n",
        "# in test phase, we don't need to compute the gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "  \n",
        "  print('Accuracy of the network on 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on 10000 test images: 80 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5P2BQd9Aso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}